# Modeling and Predicting Water Stress in Tunisia

Project goal: model and predict the level of water stress in Tunisia using World Bank environmental indicators. This repository demonstrates a full data-science workflow: data ingestion, cleaning, feature selection, time-aware model training, evaluation, and basic interpretation.

**Why this project matters**
- Water stress (freshwater withdrawals as a % of renewable freshwater resources) is a key sustainability indicator for Tunisia.
- Predicting water stress helps in planning, policy evaluation, and prioritizing interventions.

What this repo showcases
- Time-series aware machine learning with a clear temporal train/test split (train: 1960â€“2010, test: 2011â€“2024).
- Careful feature selection and preprocessing for World Bank long-format indicator data.
- Baseline models: Linear Regression, Decision Tree, Random Forest, with evaluation (MAE, RMSE, RÂ²).
- Diagnostic steps for multicollinearity and data leakage, with suggested mitigations.

Repository structure

```
tunisia_water_stress_ml/
â”œâ”€â”€ docs/                          # ğŸ“š Project documentation
â”‚   â”œâ”€â”€ PROJECT_HANDBOOK.md        # Comprehensive development guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # System design + Mermaid diagrams
â”‚   â”œâ”€â”€ DECISIONS.md               # Design decisions & trade-offs
â”‚   â””â”€â”€ API.md                     # API endpoint reference
â”‚
â”œâ”€â”€ src/                           # ğŸ§  ML Pipeline (core logic)
â”‚   â”œâ”€â”€ data_loader.py             # Load World Bank CSVs â†’ wide format
â”‚   â”œâ”€â”€ preprocessing.py           # Clean, fill missing, select features
â”‚   â”œâ”€â”€ feature_engineering.py     # Create lags, temporal features
â”‚   â”œâ”€â”€ train.py                   # Orchestrate full pipeline
â”‚   â”œâ”€â”€ evaluate.py                # Metrics & visualization
â”‚   â”œâ”€â”€ predict_future.py          # Generate forecasts
â”‚   â”œâ”€â”€ hyperparameter_tuning.py   # GridSearchCV automation
â”‚   â””â”€â”€ feature_importance.py      # Feature analysis
â”‚
â”œâ”€â”€ api/                           # ğŸš€ FastAPI REST Service
â”‚   â”œâ”€â”€ main.py                    # App entry point
â”‚   â”œâ”€â”€ config.py                  # Configuration
â”‚   â”œâ”€â”€ schemas.py                 # Request/response models
â”‚   â”œâ”€â”€ model_service.py           # Model loading & inference
â”‚   â”œâ”€â”€ dependencies.py            # Dependency injection
â”‚   â”œâ”€â”€ logging_config.py          # Logging setup
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ v1.py                  # v1 endpoints
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/                         # âœ… Test Suite
â”‚   â”œâ”€â”€ test_data_loader.py        # Data loading tests
â”‚   â”œâ”€â”€ test_preprocessing.py      # Preprocessing tests
â”‚   â”œâ”€â”€ test_feature_engineering.py# Feature engineering tests
â”‚   â”œâ”€â”€ test_pipeline_integration.py# End-to-end tests
â”‚   â”œâ”€â”€ test_api.py                # API endpoint tests
â”‚   â”œâ”€â”€ test_model_service.py      # Model service tests
â”‚   â”œâ”€â”€ test_schemas.py            # Schema validation tests
â”‚   â”œâ”€â”€ conftest.py                # Shared fixtures
â”‚   â””â”€â”€ __pycache__/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # World Bank indicator CSVs
â”‚   â”œâ”€â”€ processed/                 # Cleaned, processed data
â”‚   â””â”€â”€ DATA_VERSION.md            # Data versioning info
â”‚
â”œâ”€â”€ models/                        # ğŸ“Š Trained Models & Results
â”‚   â”œâ”€â”€ RandomForest.joblib        # Trained model
â”‚   â”œâ”€â”€ Ridge.joblib               # Regularized linear model
â”‚   â”œâ”€â”€ DecisionTree.joblib        # Decision tree model
â”‚   â”œâ”€â”€ metrics.csv                # Performance metrics (MAE, RMSE, RÂ²)
â”‚   â””â”€â”€ feature_importance_summary.csv
â”‚
â”œâ”€â”€ models_tuned/                  # Hyperparameter-tuned models
â”‚   â”œâ”€â”€ RandomForest.joblib        # Tuned model
â”‚   â”œâ”€â”€ Ridge.joblib               # Tuned model
â”‚   â”œâ”€â”€ Lasso.joblib               # Tuned model
â”‚   â”œâ”€â”€ DecisionTree.joblib        # Tuned model
â”‚   â”œâ”€â”€ metrics.csv                # Tuned model metrics
â”‚   â”œâ”€â”€ hyperparameter_tuning_summary.csv
â”‚   â”œâ”€â”€ *_cv_results.csv           # Cross-validation results
â”‚   â””â”€â”€ collinearity_dropped.txt   # Dropped features due to collinearity
â”‚
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ models_tuned/              # Additional tuned model artifacts
â”‚   â””â”€â”€ predictions/               # Future predictions & scenario analysis
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ train_config.yaml          # Training configuration
â”‚
â”œâ”€â”€ dashboard/                     # ğŸ“Š Streamlit Dashboard
â”‚   â”œâ”€â”€ app.py                     # Dashboard main app
â”‚   â”œâ”€â”€ Dockerfile                 # Dashboard container
â”‚   â”œâ”€â”€ docker-compose.yml         # Dashboard orchestration
â”‚   â”œâ”€â”€ requirements.txt           # Dashboard dependencies
â”‚   â”œâ”€â”€ components/                # Dashboard UI components
â”‚   â”œâ”€â”€ pages/                     # Dashboard pages
â”‚   â””â”€â”€ utils/                     # Dashboard utilities
â”‚
â”œâ”€â”€ notebooks/                     # ğŸ““ Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb  # EDA, data quality checks
â”‚   â”œâ”€â”€ 02_model_inspection.ipynb  # Model plots & correlation analysis
â”‚   â””â”€â”€ 03_modeling.ipynb          # Full training walkthrough
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ check_correlations.py      # Correlation analysis utility
â”‚   â””â”€â”€ predict_2030.py            # Future predictions script
â”‚
â”œâ”€â”€ .pre-commit-config.yaml        # Pre-commit hooks (black, flake8, mypy, bandit)
â”œâ”€â”€ .gitignore                     # Git ignore patterns
â”œâ”€â”€ README.md                      # Project overview (you are here)
â”œâ”€â”€ LICENSE                        # MIT License
â”œâ”€â”€ CONTRIBUTING.md                # Contribution guidelines
â”œâ”€â”€ requirements.txt               # Production dependencies
â”œâ”€â”€ api_requirements.txt           # API dependencies
â”œâ”€â”€ docker-compose.yml             # Multi-container orchestration
â”œâ”€â”€ Dockerfile                     # API container image
â”œâ”€â”€ nginx.conf                     # Reverse proxy configuration
â”œâ”€â”€ run_api.bat                    # Windows API startup script
â”œâ”€â”€ run_api.sh                     # Unix API startup script
â”‚
â””â”€â”€ docs/
    â””â”€â”€ (See above)
```

---

## Architecture Overview

**Data Flow:**
```
World Bank API (Open Data)
         â†“
   data/raw/*.csv
         â†“ (load_and_pivot)
   DataFrame (wide format)
         â†“ (preprocessing)
   Clean & selected features
         â†“ (feature_engineering)
   Lagged & temporal features
         â†“ (temporal split)
   Separate train (1960-2010) and test (2011-2024) sets
         â†“ (train.py)
   Trained models (.joblib) + metrics.csv
         â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Option 1: Batch (notebooks)         â”‚
   â”‚ Option 2: API (/v1/predict)         â”‚
   â”‚ Option 3: CLI (predict_future.py)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Temporal Split?**
- âœ“ Prevents data leakage (no future info in training)
- âœ“ Realistic evaluation (how model performs on unseen future)
- âœ— (Incorrect) Random split would artificially inflate accuracy

## Quick Start

### Option 1: Run Training Pipeline

**Step 1: Set up environment**
```powershell
# Create virtual environment
python -m venv venv

# Activate (Windows)
& venv\Scripts\Activate.ps1

# Activate (macOS/Linux)
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

**Step 2: Train models**
```powershell
# Basic training
python src/train.py

# With all options (recommended)
python src/train.py --models_dir models/ --tune_hyperparams --leakage_filter --collinearity_filter
```

**Step 3: Review results**
- Models saved to `models/` (`.joblib` files)
- Metrics in `models/metrics.csv`
- Plots in `models/` (`.png` files)
- Open `notebooks/02_model_inspection.ipynb` for visualization

### Option 2: Use REST API

**Start the API:**
```powershell
pip install -r api_requirements.txt
uvicorn api.main:app --reload
```

Navigate to `http://localhost:8000/docs` for interactive API documentation.

**Example predictions:**
```bash
curl -X POST "http://localhost:8000/v1/predict" \
  -H "Content-Type: application/json" \
  -d '{"features": {"indicator_1": 23.5, "year": 2023}, "model_name": "RandomForest"}'
```

### Option 3: Use Docker

```bash
# Build and run API container
docker-compose up -d

# API available at: http://localhost:8000
```

---

## Documentation

Complete guides available in `docs/`:

- **[PROJECT_HANDBOOK.md](docs/PROJECT_HANDBOOK.md)** â† Start here for detailed development guide
  - Development setup and environment configuration
  - Data pipeline walk-through with code examples
  - Model training options and results interpretation
  - API deployment and usage
  - Common tasks and troubleshooting

- **[ARCHITECTURE.md](docs/ARCHITECTURE.md)** - System design and data flow
  - Data pipeline diagram (Mermaid)
  - System architecture diagram
  - Component interaction flow
  - Technology stack by layer
  - Deployment architecture
  - Scalability considerations

- **[DECISIONS.md](docs/DECISIONS.md)** - Why we chose specific technologies
  - Why Ridge/Lasso over XGBoost (with data size considerations)
  - Why temporal train/test split (prevents data leakage)
  - Multicollinearity and leakage detection strategies
  - Architecture choices (FastAPI, Docker, modular design)
  - Testing and quality assurance decisions

- **[CONTRIBUTING.md](CONTRIBUTING.md)** - How to contribute
  - Git workflow and commit message format
  - Branch naming conventions
  - Type hints and code quality requirements
  - Testing requirements (100% coverage on src/)
  - Pre-commit hooks setup
